この本で触れられているプロンプトエンジニアリングの具体的な手法は、LLMの基本的な特性を理解することから始まり、プロンプトのコンテンツと構造の最適化、そしてより高度な推論や外部連携を伴うエージェント・ワークフローの設計へと発展していきます。以下に、ベーシックなものから順に整理してご説明します。

---

### I. LLMの基本的な理解とプロンプトの土台（基礎）

これは、プロンプトエンジニアリングの最も根幹となる部分であり、LLMがどのように情報を処理し、振る舞うかを理解することが重要です。

*   **LLMはテキスト補完エンジンである**
    *   **説明**: LLMの最も基本的な機能は、トレーニングデータで学習したパターンを模倣し、与えられたプロンプトに続くテキストを生成（補完）することです。人間が意図するような「思考」をしているわけではなく、統計的に最も自然な続きを予測しているに過ぎません。
    *   **具体例**: 「One, Two,」というプロンプトに対して、LLMはトレーニングデータから学習したパターンに基づいて「Buckle My Shoe」と補完します。また、テレビが壊れたという状況に対して、短編小説を学習していれば物語の続きを、会話ログを学習していればトラブルシューティングのアドバイスを返します。

*   **LLMはトークン単位でテキストを認識・処理する**
    *   **説明**: LLMは文字列を文字の並びとしてではなく、通常3～4文字の「トークン」と呼ばれる単位で認識します。このため、文字単位の厳密な処理や、人間のように一文字ずつ確認する作業は苦手です。
    *   **具体例**: 「strawberryに含まれるRの数は？」といった単純な文字カウントの質問にLLMが惑わされることがあります。また、単語内の文字を逆転させるようなタスクは、トークンを分解・再合成する必要があるため、LLMには非常に難しく、失敗しやすいです [26, 図2-6]。

*   **LLMは自己回帰モデルであり、1トークンずつ生成し、途中で修正や戻り作業ができない**
    *   **説明**: LLMは一度生成したトークンを後から修正したり取り消したりできません。人間のように途中で立ち止まって考え直すことはなく、ひたすら次のトークンを予測し続けます。
    *   **具体例**: プロンプトの途中で「直前の段落の文字数を教えてください」と尋ねても、LLMは段落を処理する時点で後からのリクエストを知らないため、読み直して正確に数えることができず、ひどく的外れな答えを返すことがあります。

*   **LLMはパターン認識に長けるが、過度な繰り返し出力が発生することがある**
    *   **説明**: LLMはパターン認識に優れているため、一度特定のパターンが出現すると、それを延々と繰り返してしまう傾向があります。モデルは飽きることがありません。
    *   **具体例**: あるテレビ番組を好む理由のリストを生成する際に、特定の単語やフレーズ（例：「遺産」「未来」「情熱的」）が延々と繰り返されるなど、極端に反復的な出力になることがあります [32, 図2-10]。

*   **ハルシネーション（幻覚）の傾向がある**
    *   **説明**: LLMは、事実とは異なるがもっともらしく聞こえる情報を、自信を持って生成してしまうことがあります。これは、LLMが提示されたプロンプトを「正しい」ものとみなして振る舞う「真実バイアス」に起因します。
    *   **具体例**: 実在しないものについて言及するプロンプトを与えると、LLMはそれが本当に存在すると仮定し、もっともらしい作り話を作り続けます。これを防ぐには、モデルに検証可能な背景情報を提供させたり、思考プロセスを明示させたりするなどの工夫が必要です。

*   **Temperature (生成の創造性を調整する数値)**
    *   **説明**: `temperature`パラメータは、モデルが次に生成するトークンを選ぶ際のランダム性の度合いを制御します。0に近いほど決定論的で安全な出力になり、1に近づくと創造性が増し、2に近づくと一貫性を失いやすくなります。
    *   **具体例**: 高い`temperature`設定で生成されたテキストは、最初は読めますが、最終的には単語としても判別不能な状態になることがあります [36, 図2-13]。

### II. プロンプトの設計と最適化（中心的なテクニック）

このセクションでは、具体的なプロンプトのコンテンツと構造をどのように設計し、LLMから期待される出力を引き出すかについて説明します。

*   **静的なコンテンツと動的なコンテンツの区別**
    *   **説明**: **静的なコンテンツ**は、タスクの定義やルールなど、常に一定で変わらない情報です。**動的なコンテンツ**は、ユーザーの入力や外部検索結果など、リクエストごとに変化するコンテキスト情報です。
    *   **具体例**: 本の推薦アプリケーションの場合、「教科書ではなく娯楽用」といったタスクの明確化が静的なコンテンツに、ユーザーが最近読んだ本や好みに関する情報が動的なコンテンツに該当します。

*   **質問の明確化 (明示的・暗黙的)**
    *   **説明**: LLMへの指示は明確かつ一貫している必要があります。直接的な指示（明示的）と、例示による指示（暗黙的）があります。
    *   **具体例**:
        *   **明示的**: 「Markdownを使用してください」「ハイパーリンクを使用しないでください」といった具体的な制約を指示します [88, 表5-1]。
        *   **暗黙的**: Few-shotプロンプティング（後述）で、期待する回答の形式やスタイルを具体例で示します。

*   **Few-shotプロンプティング**
    *   **説明**: プロンプトに複数の入力-出力例を含めることで、LLMが望ましい回答の形式やスタイル、ニュアンスを学習し、同様のタスクを正確に実行できるようになります。
    *   **具体例**: 書評のテキストとそれに対応する星の数（評価）の例を複数示すことで、モデルは書評を評価する際のトーンや基準を模倣します [91, 図5-3]。
    *   **注意点**: 大量のコンテキストを必要とする場合に扱いにくくなる、例示された情報にモデルが偏る（アンカリングバイアス）、および不適切なパターン（「単純なケースは最初に、エラーケースは後に」）を生み出す可能性があります [92-96, 図5-4, 図5-5, 図5-7]。

*   **RAG (Retrieval-Augmented Generation) - 検索拡張生成**
    *   **説明**: LLMのトレーニングデータにはない最新情報やプライベートな情報（社内ドキュメントなど）を、外部の検索システムから取得し、プロンプトに追加して知識を補強する手法です。これによりハルシネーションを減らし、より正確な回答を生成できます。
    *   **具体例**: 旅行計画アプリで、ユーザーの目的地に関する最新の渡航勧告やニュース記事の見出しを検索し、それらをプロンプトに含めることで、モデルがより適切で安全な推奨事項を提示できます [129, 表4-2]。
    *   **関連**: 語彙検索（キーワード一致）とニューラル検索（意味的類似性）があります。
    *   **注意点**: 「チェーホフの銃の誤謬」に注意が必要で、関連性のないコンテキストを含めると、モデルが無理にその情報を使おうとして、かえって誤った結果を招く可能性があります。

*   **要約**
    *   **説明**: LLMに長いテキストを短くまとめるよう指示することで、コンテキストウィンドウの制限に対応したり、情報密度の高い概要を提供したりします。
    *   **具体例**: 長いニュース記事やSNSの投稿を要約させることで、主要な情報のみを抽出し、プロンプトのトークン数を節約します。
    *   **関連**:
        *   **階層的な要約**: テキスト全体を小さな単位に分割して要約し、その要約をさらに要約していく手法です [115, 図5-13]。
        *   **特定の目的のための要約**: 最終的なアプリケーションのタスクを念頭に置いて要約を依頼することで、その目的に必要な情報が確実に残るようにします [117, 表5-3]。

*   **プロンプトの構造化 (導入部、リフォーカス、移行)**
    *   **説明**: プロンプトは単なるテキストの羅列ではなく、明確な構造を持つべきです。これにより、モデルはプロンプトの意図を正確に理解し、望ましい出力を生成しやすくなります [119, 図6-1]。
    *   **具体例**:
        *   **導入部**: プロンプトの冒頭で、これから作成するドキュメントの種類や、モデルに期待するアプローチを明確に伝えます。
        *   **リフォーカス**: 長いコンテキスト情報の後に、再度メインの質問を提示してモデルの注意を戻します。
        *   **移行**: 問題の説明から回答生成へとモデルの視点を切り替える合図を与えます（例: 回答文の冒頭を少し書き始める） [121, 122, 図6-2]。

*   **「赤ずきんの原則」**
    *   **説明**: モデルがトレーニングデータで頻繁に見た、現実的で馴染みのあるドキュメント形式やパターンにプロンプトを合わせることで、予測可能で安定した補完結果が得られます。
    *   **具体例**:
        *   **宿題の課題形式**: 旅行計画の推奨を行う際に、「# レジャー・旅行・観光 101 - 宿題課題」のような形式を用いる [128, 表4-2]。
        *   **Markdown形式**: セクションの見出し（#）やコードブロック（```）など、Markdown構文を使ってプロンプトを構造化することで、モデルが理解しやすくなります。
        *   **対話形式（ChatML）**: 「system」「user」「assistant」といった役割を明確にした対話形式でプロンプトを構成し、モデルがアシスタントとしての振る舞いを理解しやすくします。

*   **プロンプト要素間の関係 (ポジション、重要度、依存関係)**
    *   **説明**: プロンプトを構成する各情報要素（スニペット）を配置する際の考慮点です。
        *   **ポジション**: LLMはプロンプトの冒頭と末尾の情報を記憶しやすく、中間部分は忘れやすい「無関心の谷（Valley of Meh）」が存在するため、重要な情報を適切な位置に配置します。
        *   **重要度**: 各要素がモデルにどれだけ重要かを評価し、優先順位を付けます。限られたトークン予算の中で、最も価値のある情報を含めるために必要です。
        *   **依存関係**: ある要素を含める場合に必須となる他の要素（必須条件）や、同時に含めるべきではない要素（非両立条件）を管理します。

### III. プロンプトエンジニアリングの専門的なテクニック（プロンプト作成のエキスパート）

より複雑なアプリケーションや高度な推論能力をLLMに持たせるための手法です。

*   **ツールの使用 (Tool Usage)**
    *   **説明**: LLMが外部のAPIやシステムと連携し、トレーニングデータにはない最新情報にアクセスしたり、計算を実行したり、実世界に変化をもたらしたりする能力です。
    *   **具体例**: LLMに「室温を設定する」`set_room_temp`のような関数を定義して与え、モデルがユーザーの要求に応じてその関数を呼び出し、実際に部屋の温度を変更できるようにします。これにより、モデルは計算が苦手な点や、外部情報にアクセスできない点を補えます。

*   **推論の強化**
    *   **説明**: LLMに単に回答を生成させるだけでなく、その回答に至るまでの思考プロセスを明示させることで、より深く、正確な推論を促します。
    *   **具体例**:
        *   **思考の連鎖 (Chain-of-Thought, CoT) プロンプティング**: モデルに「段階的に考えよう」といった指示を与えたり、思考の例を示したりすることで、最終的な回答を出す前に問題を分解し、論理的なステップを踏んで考えるように促します。
        *   **ReAct (Reasoning and Acting)**: CoT推論と外部ツール（Action）の使用を組み合わせることで、モデルが思考と行動を交互に行い、複雑な問題を解決できるようにします。
        *   **Plan-and-Solveプロンプティング**: モデルにまず包括的な計画を立てさせてから、問題解決に取り組ませる方法です。
        *   **Branch-Solve-Mergeアプローチ**: 複数の独立したLLM（ソルバー）に同じ問題に取り組ませ、その結果を統合してより良い解決策を導き出す手法です。

*   **会話型エージェント (Conversational Agents)**
    *   **説明**: ユーザーとアシスタントが協力し、ツールを使って実世界の情報を収集したり、アクションを実行したりしながらタスクを達成するLLMベースのシステムです。
    *   **具体例**: 旅行計画エージェントが、ユーザーのメッセージ、過去の会話履歴、航空券情報などの成果物をコンテキストとして取り込み、適切なツールを呼び出して航空券を検索・予約する。
    *   **関連**: システムメッセージでエージェントの振る舞い（ペルソナ）を設定します。

*   **LLMワークフロー (LLM Workflow)**
    *   **説明**: 複雑な目標を、明確に定義された一連の小さなタスクに分解し、それらのタスクを連携させて実行することで、より大規模で複雑な問題解決を自動化するシステムです。各タスクはLLMを使用する場合も、従来のソフトウェアを使用する場合もあります。
    *   **具体例**: Shopifyプラグインのマーケティングを自動化するワークフローとして、HTML取得、店舗情報の抽出、プラグインアイデア生成、マーケティングメール作成、メール送信といったタスクを連携させます [197, 210, 図9-8]。
    *   **関連**: パイプライン（線形）、DAG（有向非巡回グラフ）、巡回グラフといったタスク接続のトポロジーがあります。

これらの手法は単独で使われるだけでなく、組み合わせてより洗練されたLLMアプリケーションを構築するために活用されます。